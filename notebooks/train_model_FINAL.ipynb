{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9439b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8842c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Setup Paths (Relative - works for everyone)\n",
    "train_dir = \"../data/Combined Dataset/train\"\n",
    "test_dir = \"../data/Combined Dataset/test\"\n",
    "model_path = \"../app/alz_resnet18.pt\"\n",
    "\n",
    "print(f\"Train dir exists: {os.path.exists(train_dir)}\")\n",
    "print(f\"Test dir exists: {os.path.exists(test_dir)}\")\n",
    "print(f\"Model file exists: {os.path.exists(model_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "print(\"Transforms ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a0fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Load Datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "\n",
    "print(f\"Training images: {len(train_dataset)}\")\n",
    "print(f\"Test images: {len(test_dataset)}\")\n",
    "print(f\"Classes: {train_dataset.class_to_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define Model Architecture\n",
    "def create_model():\n",
    "    \"\"\"Create ResNet18 model with 4 output classes\"\"\"\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    \n",
    "    # Freeze all layers initially\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Unfreeze last two blocks for fine-tuning\n",
    "    for param in model.layer3.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    for param in model.layer4.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    # Replace final layer for 4 classes\n",
    "    model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "model = create_model()\n",
    "print(\"Model architecture ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a15363",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ”’ Load Existing Model or Train New One\n",
    "**By default, this loads the existing trained model. Only set TRAIN=True if you need to retrain.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a7ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Load or Train Model\n",
    "TRAIN = False  # âš ï¸ Set to True ONLY if you want to retrain from scratch\n",
    "\n",
    "if os.path.exists(model_path) and not TRAIN:\n",
    "    print(\"âœ… Loading existing trained model...\")\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "else:\n",
    "    if TRAIN:\n",
    "        print(\"âš ï¸ WARNING: Training new model (this will overwrite existing model!)\")\n",
    "    else:\n",
    "        print(\"Model file not found. Training new model...\")\n",
    "    \n",
    "    # Setup training\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=1e-5\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 5\n",
    "    print(f\"Training for {num_epochs} epochs...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save trained model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"\\nâœ… Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba62225",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“Š Model Evaluation\n",
    "**This section evaluates the model on the test set and prints metrics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53b3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Prepare Test DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "print(f\"Test loader ready with {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Run Evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "print(\"Running evaluation on test set...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "print(f\"Evaluated {len(all_labels)} test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030cff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Calculate Metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Class names\n",
    "class_names = ['Mild Impairment', 'Moderate Impairment', 'No Impairment', 'Very Mild Impairment']\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"ðŸ“Š MODEL EVALUATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nâœ… Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"âœ… F1-Score (weighted): {f1:.4f}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸ“‹ Confusion Matrix:\")\n",
    "print(\"=\"*50)\n",
    "print(cm)\n",
    "print(\"\\nRows = True Labels, Columns = Predicted Labels\")\n",
    "print(f\"Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e61a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Detailed Classification Report\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸ“ˆ DETAILED CLASSIFICATION REPORT\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1362ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Per-Class Accuracy\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸŽ¯ PER-CLASS ACCURACY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_correct = cm[i, i]\n",
    "    class_total = cm[i].sum()\n",
    "    class_acc = class_correct / class_total if class_total > 0 else 0\n",
    "    print(f\"{class_name:25s}: {class_acc:.4f} ({class_acc*100:.2f}%) - {class_correct}/{class_total} correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7d5294",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ… Summary\n",
    "\n",
    "This notebook:\n",
    "- âœ… Uses **relative paths** (reproducible across machines)\n",
    "- âœ… Loads **existing trained model** by default (safe)\n",
    "- âœ… Includes **training guard** to prevent accidental retraining\n",
    "- âœ… Evaluates on **test set**\n",
    "- âœ… Prints **accuracy, F1-score, confusion matrix**\n",
    "- âœ… Saves model to **`../app/alz_resnet18.pt`**\n",
    "\n",
    "**Ready for your report! ðŸŽ‰**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
